name: scrape

on:
  schedule:
    - cron: '30 */2 * * *'  # Run every 2 hours at 30 minutes past the hour
  workflow_dispatch:

permissions:
  contents: write  # Allow the bot to push changes to the repo
  pages: write
  id-token: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Check out this repo
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      # Install dependencies (if you have any)
      - name: Install dependencies
        run: |
          pip install selenium beautifulsoup4 webdriver-manager

      - name: Run the scraper
        run: python scraper.py

      - name: Configure Git
        run: |
          git config user.name "Automated"
          git config user.email "actions@users.noreply.github.com"

      - name: Check for changes in README.md
        run: |
          cat README.md  # This will print the content of the README.md file before any changes
          
      - name: Commit changes
        run: |
          git add README.md
          git status  # Check the status before committing
          if [[ \`git status --porcelain\` ]]; then
            git commit -m "Updated commits number"
            git push
          else
            echo "No changes to commit"
          fi

